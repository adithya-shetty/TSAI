{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Architecture_Basics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuGWcUSJ-efk",
        "colab_type": "text"
      },
      "source": [
        "### Install Keras module for python and import it to run basic keras functions for model building."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-wujMov-fPZ",
        "colab_type": "text"
      },
      "source": [
        "### Import Numpy library which is usually used to store data. Also import other support libraries in keras for model building and predefined dataset loading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "aaedca40-a5a3-4d27-b3ba-967cbb00aa3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz4pK7Cf-i21",
        "colab_type": "text"
      },
      "source": [
        "### Matplotlib is a visualization tool of python which can be used to plot graphs and display images. Here we first print the total number of images used for training. Then import matplotlib library and show the first training image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "39d90162-28ba-4718-9ca7-81b691786147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f726e284b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4F7Bxaa-jsy",
        "colab_type": "text"
      },
      "source": [
        "### As the dataset contains single channel images, we reshape array to correct the input channel dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw4zfyXA-lMg",
        "colab_type": "text"
      },
      "source": [
        "### Normalize values between 0 to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH6kaAt2-mH1",
        "colab_type": "text"
      },
      "source": [
        "### Show labels of last 10 train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "1dc38b5f-0893-45d8-ed76-fec259b83e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR-bHYIT-m3E",
        "colab_type": "text"
      },
      "source": [
        "### Convert 1-dimensional class arrays to 10-dimensional class matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2HoAuIP-nfv",
        "colab_type": "text"
      },
      "source": [
        "### Show the matrix converted labels of last 10 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "960de895-eb66-4fe0-8290-6dc8e18a83df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq69nxr7-oW_",
        "colab_type": "text"
      },
      "source": [
        "### Vanilla Network\n",
        "**Expectations:**\n",
        "\n",
        "\n",
        "*   Have high parameters\n",
        "*   Low validation accuracy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG4I_hr4wwhF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "027b48a1-753e-4e2b-bdb8-5d10a2af6dfd"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu')) #24\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#12\n",
        "model.add(Convolution2D(16, 1, 1, activation='relu')) #12\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))#10\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))#8\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))#6\n",
        "\n",
        "model.add(Convolution2D(10, 6, 6))\n",
        "#keras.layers.AveragePooling2D(pool_size=(4, 4))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_449 (Conv2D)          (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_450 (Conv2D)          (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_64 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_451 (Conv2D)          (None, 12, 12, 16)        528       \n",
            "_________________________________________________________________\n",
            "conv2d_452 (Conv2D)          (None, 10, 10, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_453 (Conv2D)          (None, 8, 8, 64)          18496     \n",
            "_________________________________________________________________\n",
            "conv2d_454 (Conv2D)          (None, 6, 6, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_455 (Conv2D)          (None, 1, 1, 10)          23050     \n",
            "_________________________________________________________________\n",
            "flatten_64 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_64 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 88,442\n",
            "Trainable params: 88,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (6, 6))`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN5MQLm6I2ob",
        "colab_type": "text"
      },
      "source": [
        "#### Configuring the remaining hyperparameters for model like loss function, optimizer and run training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSVXwNk1I1dO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0d0f152b-a784-47b6-9bdc-9d4d10e382da"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 34s 568us/step - loss: 0.1407 - acc: 0.9567 - val_loss: 0.0561 - val_acc: 0.9825\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 20s 341us/step - loss: 0.0447 - acc: 0.9857 - val_loss: 0.0445 - val_acc: 0.9853\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 20s 335us/step - loss: 0.0331 - acc: 0.9900 - val_loss: 0.0357 - val_acc: 0.9893\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 20s 336us/step - loss: 0.0256 - acc: 0.9921 - val_loss: 0.0272 - val_acc: 0.9898\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 20s 337us/step - loss: 0.0209 - acc: 0.9936 - val_loss: 0.0242 - val_acc: 0.9919\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 20s 334us/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0354 - val_acc: 0.9893\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 20s 330us/step - loss: 0.0157 - acc: 0.9948 - val_loss: 0.0251 - val_acc: 0.9922\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 20s 329us/step - loss: 0.0117 - acc: 0.9966 - val_loss: 0.0466 - val_acc: 0.9888\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 20s 328us/step - loss: 0.0113 - acc: 0.9963 - val_loss: 0.0295 - val_acc: 0.9918\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.0097 - acc: 0.9972 - val_loss: 0.0335 - val_acc: 0.9919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f71b850d9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhrXvI9BL8T4",
        "colab_type": "text"
      },
      "source": [
        "###Result :\n",
        "**Max val. accuracy**: 0.9922\n",
        "**Parameters**: 88k\n",
        "####*Next Goal*: Reduce parameters below 15k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H2ELMq-NMET",
        "colab_type": "text"
      },
      "source": [
        "###First Improvement\n",
        "\n",
        "\n",
        "*   Reduce kernel size\n",
        "*   Increase batch size, epochs\n",
        "\n",
        "**Expectations:**\n",
        "\n",
        "\n",
        "*   Reduced parameters\n",
        "*   Higher validation accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtJ8T_doN7fM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "44cc8c15-28ea-482b-8e4a-6e50372c04e2"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #24\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#12\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu')) #12\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu'))#10\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#8\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#6\n",
        "\n",
        "model.add(Convolution2D(10, 6, 6))\n",
        "#keras.layers.AveragePooling2D(pool_size=(4, 4))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_456 (Conv2D)          (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "conv2d_457 (Conv2D)          (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_65 (MaxPooling (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_458 (Conv2D)          (None, 12, 12, 10)        170       \n",
            "_________________________________________________________________\n",
            "conv2d_459 (Conv2D)          (None, 10, 10, 8)         728       \n",
            "_________________________________________________________________\n",
            "conv2d_460 (Conv2D)          (None, 8, 8, 16)          1168      \n",
            "_________________________________________________________________\n",
            "conv2d_461 (Conv2D)          (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "conv2d_462 (Conv2D)          (None, 1, 1, 10)          5770      \n",
            "_________________________________________________________________\n",
            "flatten_65 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_65 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 11,712\n",
            "Trainable params: 11,712\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (6, 6))`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ_TVgfDOAin",
        "colab_type": "text"
      },
      "source": [
        "#### Configuring the remaining hyperparameters for model like loss function, optimizer and run training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrOZQBf0OE8E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "78ad71c2-cafa-41bd-85ff-47580e9c195e"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=15, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 19s 324us/step - loss: 0.3236 - acc: 0.9005 - val_loss: 0.1022 - val_acc: 0.9675\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0936 - acc: 0.9717 - val_loss: 0.0800 - val_acc: 0.9741\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0693 - acc: 0.9787 - val_loss: 0.0493 - val_acc: 0.9844\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0551 - acc: 0.9837 - val_loss: 0.0446 - val_acc: 0.9864\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0481 - acc: 0.9852 - val_loss: 0.0524 - val_acc: 0.9830\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0414 - acc: 0.9873 - val_loss: 0.0417 - val_acc: 0.9863\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0354 - acc: 0.9890 - val_loss: 0.0335 - val_acc: 0.9887\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0339 - acc: 0.9894 - val_loss: 0.0349 - val_acc: 0.9894\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0298 - acc: 0.9901 - val_loss: 0.0319 - val_acc: 0.9903\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0276 - acc: 0.9908 - val_loss: 0.0320 - val_acc: 0.9894\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0246 - acc: 0.9920 - val_loss: 0.0324 - val_acc: 0.9902\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0231 - acc: 0.9923 - val_loss: 0.0327 - val_acc: 0.9893\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0208 - acc: 0.9932 - val_loss: 0.0377 - val_acc: 0.9883\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0195 - acc: 0.9936 - val_loss: 0.0311 - val_acc: 0.9900\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0180 - acc: 0.9939 - val_loss: 0.0385 - val_acc: 0.9883\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f71b7e0f6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM3R3zHcPd7O",
        "colab_type": "text"
      },
      "source": [
        "###Result :\n",
        "**Max val. accuracy**: 0.9903\n",
        "**Parameters:** 11k\n",
        "\n",
        "####*Next Goal*: Increase validation accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXc94I8QQkep",
        "colab_type": "text"
      },
      "source": [
        "###Second Improvement\n",
        "\n",
        "*   Change learning rate dynamically\n",
        "\n",
        "**Expectation:**\n",
        "\n",
        "\n",
        "*   Improvement in validation accuracy\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh5_AUhER86o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "0587288c-d554-426c-df66-0cb0eec89595"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #24\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#12\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu')) #12\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu'))#10\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#8\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#6\n",
        "\n",
        "model.add(Convolution2D(10, 6, 6))\n",
        "#keras.layers.AveragePooling2D(pool_size=(4, 4))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_463 (Conv2D)          (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "conv2d_464 (Conv2D)          (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_66 (MaxPooling (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_465 (Conv2D)          (None, 12, 12, 10)        170       \n",
            "_________________________________________________________________\n",
            "conv2d_466 (Conv2D)          (None, 10, 10, 8)         728       \n",
            "_________________________________________________________________\n",
            "conv2d_467 (Conv2D)          (None, 8, 8, 16)          1168      \n",
            "_________________________________________________________________\n",
            "conv2d_468 (Conv2D)          (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "conv2d_469 (Conv2D)          (None, 1, 1, 10)          5770      \n",
            "_________________________________________________________________\n",
            "flatten_66 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_66 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 11,712\n",
            "Trainable params: 11,712\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (6, 6))`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k667f350-qbL",
        "colab_type": "text"
      },
      "source": [
        "#### Configuring the remaining hyperparameters for model like loss function, optimizer and run training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "outputId": "d52c4d85-9bbd-41b4-fbd1-2a707dfc3ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=15, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 26s 433us/step - loss: 0.2436 - acc: 0.9243 - val_loss: 0.0769 - val_acc: 0.9752\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0748 - acc: 0.9768 - val_loss: 0.0621 - val_acc: 0.9799\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0522 - acc: 0.9839 - val_loss: 0.0470 - val_acc: 0.9849\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0418 - acc: 0.9875 - val_loss: 0.0448 - val_acc: 0.9847\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0354 - acc: 0.9886 - val_loss: 0.0359 - val_acc: 0.9877\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0305 - acc: 0.9904 - val_loss: 0.0369 - val_acc: 0.9880\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0258 - acc: 0.9918 - val_loss: 0.0396 - val_acc: 0.9873\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0234 - acc: 0.9925 - val_loss: 0.0422 - val_acc: 0.9874\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0204 - acc: 0.9933 - val_loss: 0.0422 - val_acc: 0.9877\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0182 - acc: 0.9941 - val_loss: 0.0359 - val_acc: 0.9884\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0155 - acc: 0.9953 - val_loss: 0.0396 - val_acc: 0.9877\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0417 - val_acc: 0.9883\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0122 - acc: 0.9962 - val_loss: 0.0444 - val_acc: 0.9875\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0106 - acc: 0.9966 - val_loss: 0.0404 - val_acc: 0.9885\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0091 - acc: 0.9971 - val_loss: 0.0408 - val_acc: 0.9905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f71b7e20c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwbSeQFdSty8",
        "colab_type": "text"
      },
      "source": [
        "###Result :\n",
        "**Max val. accuracy:** 0.9905\n",
        "**Parameters:** 11k\n",
        "\n",
        "####*Next Goal:* Address Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA9y0qf4TonJ",
        "colab_type": "text"
      },
      "source": [
        "###Final Improvement\n",
        "\n",
        "*   Add Dropout for Regularization\n",
        "*   Add Batch normalization\n",
        "\n",
        "**Expectations:**\n",
        "\n",
        "*   Hopeful of getting accuracy above 99.4\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGkKicb2VEkf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "3cd928de-d36d-4e6e-d7d6-447a52d6add3"
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#12\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu')) #12\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu'))#10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#8\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))#6\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 6, 6))\n",
        "#keras.layers.AveragePooling2D(pool_size=(4, 4))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_470 (Conv2D)          (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_250 (Bat (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_471 (Conv2D)          (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_251 (Bat (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_67 (MaxPooling (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_472 (Conv2D)          (None, 12, 12, 10)        170       \n",
            "_________________________________________________________________\n",
            "conv2d_473 (Conv2D)          (None, 10, 10, 8)         728       \n",
            "_________________________________________________________________\n",
            "batch_normalization_252 (Bat (None, 10, 10, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_474 (Conv2D)          (None, 8, 8, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_253 (Bat (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_168 (Dropout)        (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_475 (Conv2D)          (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_254 (Bat (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_476 (Conv2D)          (None, 1, 1, 10)          5770      \n",
            "_________________________________________________________________\n",
            "flatten_67 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_67 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 11,976\n",
            "Trainable params: 11,844\n",
            "Non-trainable params: 132\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (6, 6))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNaYSByjWTaw",
        "colab_type": "text"
      },
      "source": [
        "#### Configuring the remaining hyperparameters for model like loss function, optimizer and run training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmIcc9JMWWKm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1994f3b2-2552-46cf-a070-379a6096b113"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=15, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 29s 480us/step - loss: 0.1604 - acc: 0.9495 - val_loss: 0.0662 - val_acc: 0.9810\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0546 - acc: 0.9831 - val_loss: 0.0463 - val_acc: 0.9865\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0391 - acc: 0.9878 - val_loss: 0.0315 - val_acc: 0.9900\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0329 - acc: 0.9898 - val_loss: 0.0330 - val_acc: 0.9892\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0281 - acc: 0.9911 - val_loss: 0.0293 - val_acc: 0.9897\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0247 - acc: 0.9920 - val_loss: 0.0309 - val_acc: 0.9905\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0209 - acc: 0.9932 - val_loss: 0.0304 - val_acc: 0.9908\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.0266 - val_acc: 0.9916\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0175 - acc: 0.9946 - val_loss: 0.0210 - val_acc: 0.9941\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0216 - val_acc: 0.9930\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0146 - acc: 0.9954 - val_loss: 0.0259 - val_acc: 0.9921\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0134 - acc: 0.9959 - val_loss: 0.0222 - val_acc: 0.9927\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0129 - acc: 0.9958 - val_loss: 0.0214 - val_acc: 0.9938\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0121 - acc: 0.9961 - val_loss: 0.0229 - val_acc: 0.9936\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.0234 - val_acc: 0.9933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f71b6fe58d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf3q9Gz5XQRL",
        "colab_type": "text"
      },
      "source": [
        "###Result :\n",
        "**Max val. accuracy:** 0.9941 \n",
        "**Parameters:** 11k\n",
        "\n",
        "###*Goals Acheived in 9th Epoch*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axaV8UUJ-sFD",
        "colab_type": "text"
      },
      "source": [
        "### Calculate the validation score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fab6fb34-fb48-41de-d5b3-90fbf7c79960"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.023391957638942768, 0.9933]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDydXL1h-t4K",
        "colab_type": "text"
      },
      "source": [
        "### Predict the label for the test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "b6d4d7ad-4836-49de-905b-93c580cfbdb4"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.31687395e-11 2.03458566e-08 4.01254070e-08 5.23186259e-08\n",
            "  2.50984292e-13 5.88469681e-12 3.55234261e-13 9.99999642e-01\n",
            "  3.26892097e-10 2.09893912e-07]\n",
            " [7.03695306e-08 6.20535303e-08 9.99999881e-01 1.11740944e-12\n",
            "  8.11071002e-11 2.68622066e-13 3.25813154e-08 1.01331039e-13\n",
            "  2.15821999e-10 4.91432253e-14]\n",
            " [1.54449464e-09 9.99997497e-01 3.67052948e-08 1.11970024e-08\n",
            "  1.81761936e-06 7.51524343e-10 3.82032482e-07 1.92344373e-07\n",
            "  7.45145030e-08 2.40392524e-08]\n",
            " [9.99988198e-01 1.39345979e-09 2.42583070e-07 1.70093291e-08\n",
            "  1.17296617e-08 7.23766718e-08 1.09256753e-05 3.87678423e-09\n",
            "  6.27894181e-08 5.68464714e-07]\n",
            " [5.11522248e-12 3.50892492e-12 2.30997461e-11 2.39487165e-14\n",
            "  1.00000000e+00 2.46858469e-14 9.25871324e-11 7.15978969e-12\n",
            "  1.63339893e-12 8.34226910e-09]\n",
            " [3.68760161e-11 9.99998808e-01 2.56535593e-08 1.73119560e-10\n",
            "  4.53679746e-07 1.78416049e-11 1.68966281e-08 6.85077794e-07\n",
            "  1.42756529e-09 9.13624731e-09]\n",
            " [8.27597406e-16 1.53214312e-08 3.32645397e-13 9.81852471e-15\n",
            "  9.99999642e-01 2.99523362e-12 1.12226980e-13 3.42961132e-10\n",
            "  3.59803778e-07 1.20518546e-08]\n",
            " [4.92011853e-09 1.83973903e-08 4.07282847e-08 3.50737679e-08\n",
            "  9.58828750e-05 1.27931816e-08 4.80936471e-12 1.64964518e-07\n",
            "  2.72808531e-08 9.99903798e-01]\n",
            " [9.67038432e-06 1.73596593e-09 3.54830902e-08 3.60711483e-09\n",
            "  2.59843946e-09 9.87601161e-01 8.40779580e-03 1.29932671e-11\n",
            "  3.97670828e-03 4.69588895e-06]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq1FeWTz-vjW",
        "colab_type": "text"
      },
      "source": [
        "### Saving layer names in a dict datatype so that we can later use it for visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbyMd_EQ-wrP",
        "colab_type": "text"
      },
      "source": [
        "### Code to Visualise the kernel extracted features of a particular layer and input images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "outputId": "0356f827-b7fd-4e5a-bb82-9775632d2410"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_475'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwoAAALUCAYAAACre8XKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x864 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}